{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 of the Civil Asset Forfeiture analysis. This script takes in the manually cleaned sheet and generates final summary tables. \n",
    "\n",
    "Last edited by Sophie Bair 10/26/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caf = pd.read_excel('caf_pt2_input.xlsx')\n",
    "caf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create crosstabs of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2a. demographic breakdown + how demographic vars correlate with representation, understanding of case, and outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_gender = pd.crosstab(index=caf['litigant_race'], columns=caf['litigant_gender'], margins=True)\n",
    "race_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do race/gender correlate with representation in any way? \n",
    "\n",
    "pd.crosstab(index=caf['litigant_race'], columns=caf['atty_present'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_yes_no = caf[caf['atty_present'] != 'Not sure']\n",
    "atty_race_count = pd.crosstab(index=only_yes_no['litigant_race'], columns=only_yes_no['atty_present'], margins=True)\n",
    "atty_race_pct = pd.crosstab(index=only_yes_no['litigant_race'], columns=only_yes_no['atty_present'], normalize='index', margins=True)\n",
    "atty_race_pct # removing observations that were unsure, black defendents seem to have higher rates of pro se representation at first glance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=only_yes_no['litigant_gender'], columns=only_yes_no['atty_present'], normalize='index', margins=True)\n",
    "# seems pretty consistent across males and females "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does race/gender correlate with outcomes? \n",
    "\n",
    "caf_settled_subset = caf[caf['case_settled_or_resolved_explanation_transcribed'].isin(['dismissed', 'rule in favor of the claimant', 'rule in favor of the state', 'settlement', 'state declined to pursue'])]\n",
    "pd.crosstab(columns=caf_settled_subset['case_settled_or_resolved_explanation_transcribed'], index=caf['litigant_race'])\n",
    "# honestly, i think n sizes are going to be too small to say anything here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=caf['litigant_race'], columns=caf['litigant_understanding'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=caf['litigant_race'], columns=caf['litigant_understanding'],  normalize='index', margins=True)\n",
    "# white defendents had highest rates of understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=caf['litigant_gender'], columns=caf['litigant_understanding'],  normalize='index', margins=True)\n",
    "# gender is pretty even "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b. do different judges have different rates of litigant outcomes/understanding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind of tangential, but curious if court-watchers with lots of observations are just observing one judge \n",
    "# (and thus could be skewing data a bit) or if it's evenly distributed (would make for better comparison)\n",
    "pd.crosstab(columns=caf['name_cleaned'], index=caf['judge_name_cleaned'], normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(columns=caf['name_cleaned'], index=caf['judge_name_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some heavy hitters (such as Alessandra) do overwhelmingly observe one judge - could be skewing results for judge carroll\n",
    "# however a lot do seem more balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(columns=caf_settled_subset['case_settled_or_resolved_explanation_transcribed'], index=caf_settled_subset['judge_name_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(columns=caf_settled_subset['case_settled_or_resolved_explanation_transcribed'], index=caf_settled_subset['judge_name_cleaned'], normalize='index')\n",
    "# generally judge carroll is more likely to rule in favor of the state, and judge patton is much more likely to get the state to decline to pursue\n",
    "# could perform a significance test if this is of interest but almost certainly not going to be able to say anything with these n-sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(columns=caf['litigant_understanding'], index=caf['judge_name_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(columns=caf['litigant_understanding'], index=caf['judge_name_cleaned'], normalize='index')\n",
    "# despite the qualitative reports, judge carroll has a relatively high rate of litigant understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2c. breakdown of seizing entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isp_seizing_entity = pd.crosstab(index=caf['isp_district_cleaned'], columns=caf['seizing_entity'])\n",
    "suburban_seizing_entity = pd.crosstab(index=caf['suburban_district_cleaned'], columns=caf['seizing_entity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d. summaries of categorical data relating to case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_seized = pd.DataFrame(caf[['vehicle_seized', 'cash_seized', 'drugs_seized', 'real_estate_seized', 'weapons_seized', 'other_property_seized']].count(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(caf[caf['na_seized'] != 1]) # total number of cases where property was identifeid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_reason = pd.DataFrame(caf[['drugs', 'aggravated_fleeing_eluding','dui','driving_without_license','burglary','robbery','violence','gun_possession','involved_in_accident','money_laundering','speeding_or_traffic_violation','traffic_stop','violating_probation']].sum(axis=0).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('tab_results.xlsx')\n",
    "# single tables \n",
    "for i in ['judge_name_cleaned', 'atty_present', 'party', 'jointly_owned_property', 'probable_cause_hearing', 'probable_cause_established', 'fee_waiver_filed', 'fee_waiver_filed_explanation_transcribed', 'hardship_exception_requested', 'case_settled_or_resolved', 'case_settled_or_resolved_explanation_transcribed', 'fine_fee_issues_cleaned', 'zoom_difficulties', 'admin_difficulties', 'litigant_understanding', 'seizing_entity']:\n",
    "    tab = pd.crosstab(index=caf[i], columns='count').sort_values('count', ascending=False)\n",
    "    if len(i) < 32: # some column names are too long \n",
    "        tab.to_excel(writer, sheet_name=i)\n",
    "    else:\n",
    "        tab.to_excel(writer, sheet_name=i[0:31])\n",
    "        \n",
    "# cross tables \n",
    "race_gender.to_excel(writer, sheet_name='race_gender')\n",
    "isp_seizing_entity.to_excel(writer, sheet_name='isp_seizing_entity')\n",
    "suburban_seizing_entity.to_excel(writer, sheet_name='suburban_seizing_entity')\n",
    "property_seized.to_excel(writer, sheet_name='property_seized')\n",
    "seizure_reason.to_excel(writer, sheet_name='seizure_reason')\n",
    "\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
